
CondaError: Run 'conda init' before 'conda activate'

Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:05,  1.78s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:04<00:04,  2.13s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:06<00:02,  2.06s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.63s/it]
You shouldn't move a model that is dispatched using accelerate hooks.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]Loading checkpoint shards:   3%|▎         | 1/30 [00:01<00:42,  1.47s/it]Loading checkpoint shards:   7%|▋         | 2/30 [00:03<00:45,  1.63s/it]Loading checkpoint shards:  10%|█         | 3/30 [00:05<00:46,  1.70s/it]Loading checkpoint shards:  13%|█▎        | 4/30 [00:06<00:42,  1.65s/it]Loading checkpoint shards:  17%|█▋        | 5/30 [00:08<00:39,  1.58s/it]Loading checkpoint shards:  20%|██        | 6/30 [00:09<00:39,  1.64s/it]Loading checkpoint shards:  23%|██▎       | 7/30 [00:11<00:37,  1.61s/it]Loading checkpoint shards:  27%|██▋       | 8/30 [00:13<00:36,  1.64s/it]Loading checkpoint shards:  30%|███       | 9/30 [00:15<00:38,  1.83s/it]Loading checkpoint shards:  33%|███▎      | 10/30 [00:16<00:34,  1.72s/it]Loading checkpoint shards:  37%|███▋      | 11/30 [00:18<00:31,  1.67s/it]Loading checkpoint shards:  40%|████      | 12/30 [00:20<00:31,  1.78s/it]Loading checkpoint shards:  43%|████▎     | 13/30 [00:22<00:30,  1.78s/it]Loading checkpoint shards:  47%|████▋     | 14/30 [00:23<00:27,  1.74s/it]Loading checkpoint shards:  50%|█████     | 15/30 [00:25<00:27,  1.80s/it]Loading checkpoint shards:  53%|█████▎    | 16/30 [00:27<00:25,  1.81s/it]Loading checkpoint shards:  57%|█████▋    | 17/30 [00:29<00:23,  1.84s/it]Loading checkpoint shards:  60%|██████    | 18/30 [00:31<00:24,  2.02s/it]Loading checkpoint shards:  63%|██████▎   | 19/30 [00:33<00:21,  1.98s/it]Loading checkpoint shards:  67%|██████▋   | 20/30 [00:36<00:20,  2.08s/it]Loading checkpoint shards:  70%|███████   | 21/30 [00:38<00:19,  2.13s/it]Loading checkpoint shards:  73%|███████▎  | 22/30 [00:40<00:17,  2.22s/it]Loading checkpoint shards:  77%|███████▋  | 23/30 [00:42<00:15,  2.20s/it]Loading checkpoint shards:  80%|████████  | 24/30 [00:45<00:13,  2.28s/it]Loading checkpoint shards:  83%|████████▎ | 25/30 [00:47<00:10,  2.17s/it]Loading checkpoint shards:  87%|████████▋ | 26/30 [00:49<00:08,  2.10s/it]Loading checkpoint shards:  90%|█████████ | 27/30 [00:51<00:06,  2.02s/it]Loading checkpoint shards:  93%|█████████▎| 28/30 [00:52<00:03,  1.96s/it]Loading checkpoint shards:  97%|█████████▋| 29/30 [00:54<00:01,  1.97s/it]Loading checkpoint shards: 100%|██████████| 30/30 [00:55<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 30/30 [00:55<00:00,  1.86s/it]
You shouldn't move a model that is dispatched using accelerate hooks.
Traceback (most recent call last):
  File "/ibex/user/feic/pjs/Speculative-decoding/Speculative-decoding-database/src/main.py", line 22, in <module>
    approx_tokenizer, approx_model, target_tokenizer, target_model = load_model(model_list['llama3-8b'], model_list['llama3-70b'])
  File "/ibex/user/feic/pjs/Speculative-decoding/Speculative-decoding-database/src/run.py", line 38, in load_model
    trust_remote_code=False).to(device)
  File "/ibex/user/feic/conda-environments/torch_env/lib/python3.10/site-packages/accelerate/big_modeling.py", line 456, in wrapper
    return fn(*args, **kwargs)
  File "/ibex/user/feic/conda-environments/torch_env/lib/python3.10/site-packages/transformers/modeling_utils.py", line 2724, in to
    return super().to(*args, **kwargs)
  File "/ibex/user/feic/conda-environments/torch_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1173, in to
    return self._apply(convert)
  File "/ibex/user/feic/conda-environments/torch_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 779, in _apply
    module._apply(fn)
  File "/ibex/user/feic/conda-environments/torch_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 779, in _apply
    module._apply(fn)
  File "/ibex/user/feic/conda-environments/torch_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 779, in _apply
    module._apply(fn)
  [Previous line repeated 2 more times]
  File "/ibex/user/feic/conda-environments/torch_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 804, in _apply
    param_applied = fn(param)
  File "/ibex/user/feic/conda-environments/torch_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1159, in convert
    return t.to(
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 448.00 MiB. GPU 
